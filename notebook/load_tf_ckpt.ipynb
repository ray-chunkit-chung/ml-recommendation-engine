{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    IntegerLookup,\n",
    "    Embedding,\n",
    "    Flatten,\n",
    "    Dot,\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"../local/train.csv\"\n",
    "TEST_PATH = \"../local/test.csv\"\n",
    "MODEL_PATH = \"../local/model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_model():\n",
    "    \"\"\"\n",
    "    A dummy pre-trained model for testing purposes.\n",
    "    \"\"\"\n",
    "    # Assuming you have a CSV file with columns: 'user_id', 'movie_id', 'rating'\n",
    "    train = pd.read_csv(TRAIN_PATH)\n",
    "    test = pd.read_csv(TEST_PATH)\n",
    "\n",
    "    # Unique users and movies\n",
    "    all_users = train[\"user_id\"].unique()\n",
    "    all_movies = train[\"movie_id\"].unique()\n",
    "\n",
    "    # Create user and movie input layers\n",
    "    user_input = Input(shape=(1,), name=\"user_input\")\n",
    "    movie_input = Input(shape=(1,), name=\"movie_input\")\n",
    "\n",
    "    # Create user and movie IntegerLookup\n",
    "    user_as_integer = IntegerLookup(vocabulary=all_users)(user_input)\n",
    "    movie_as_integer = IntegerLookup(vocabulary=all_movies)(movie_input)\n",
    "\n",
    "    # Create user and movie embeddings\n",
    "    user_embedding = Embedding(input_dim=len(all_users) + 1, output_dim=32)(user_as_integer)\n",
    "    movie_embedding = Embedding(input_dim=len(all_movies) + 1, output_dim=32)(\n",
    "        movie_as_integer\n",
    "    )\n",
    "\n",
    "    # Create the recommendation model (dot product of user and movie embeddings)\n",
    "    dot_product = Dot(axes=2)([user_embedding, movie_embedding])\n",
    "\n",
    "    # Flatten the dot_product\n",
    "    flatten = Flatten()(dot_product)\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = Model(inputs=[user_input, movie_input], outputs=flatten)\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "125/125 [==============================] - 1s 3ms/step - loss: 13.7102 - val_loss: 14.3169\n",
      "Epoch 2/10\n",
      " 77/125 [=================>............] - ETA: 0s - loss: 13.6731"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/com.docker.devenvironments.code/.venv/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 3ms/step - loss: 13.5462 - val_loss: 14.2202\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 12.3926 - val_loss: 13.6838\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.3356 - val_loss: 12.6020\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 5.6904 - val_loss: 11.4976\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.2669 - val_loss: 10.7477\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.0940 - val_loss: 10.3185\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.5140 - val_loss: 10.0543\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.1879 - val_loss: 9.8974\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.9846 - val_loss: 9.7886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f31bca5be10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A dummy pre-trained model\n",
    "model = load_model()\n",
    "\n",
    "# Load a small batch of data\n",
    "train = pd.read_csv(TRAIN_PATH, nrows=10000) \n",
    "test = pd.read_csv(TEST_PATH, nrows=10000)\n",
    "\n",
    "# Train the model\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint(MODEL_PATH, monitor=\"val_loss\", save_best_only=True)\n",
    "model.fit(\n",
    "    [train[\"user_id\"], train[\"movie_id\"]],\n",
    "    train[\"user_rating\"],\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop, checkpoint],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
